{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c94223",
   "metadata": {},
   "source": [
    "# Precompute all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a70dda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................['UCSF-PDGM-0138', 'UCSF-PDGM-0175', 'UCSF-PDGM-0181', 'UCSF-PDGM-0278', 'UCSF-PDGM-0289', 'UCSF-PDGM-0315']\n",
      "494\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure # For marching cubes\n",
    "import polyscope as ps # For mesh display\n",
    "from persim import plot_diagrams, PersistenceImager\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import skimage\n",
    "import skimage.io\n",
    "sys.path.append(\"../src\")\n",
    "import glob\n",
    "from geomstats import *\n",
    "from topostats import *\n",
    "from kernels import *\n",
    "from utils3d import *\n",
    "\n",
    "\n",
    "def load_dictionary(metadata_path):\n",
    "    df = pd.read_csv(metadata_path)\n",
    "    data = {}\n",
    "    for index, row in df.iterrows():\n",
    "        patient_id = row[\"ID\"]\n",
    "        patient_id = \"M-0\".join(patient_id.split(\"M-\")) #File paths have an extra 0 in ID\n",
    "        data[patient_id] = row\n",
    "    del data[\"UCSF-PDGM-0541\"] # Skip Patient 541 because segmentation file is empty\n",
    "    return data\n",
    "\n",
    "def argsort(seq):\n",
    "    return np.array(sorted(range(len(seq)), key=seq.__getitem__), dtype=int)\n",
    "\n",
    "metadata_path = \"../Data/UCSF-PDGM-metadata_v2.csv\"\n",
    "all_data_path = \"../Data/UCSF-PDGM-v3\"\n",
    "data = load_dictionary(metadata_path) \n",
    "\n",
    "patients = list(data.keys())\n",
    "diagnosis = [data[p][\"Final pathologic diagnosis (WHO 2021)\"] for p in patients]\n",
    "dead = np.array([data[p][\"1-dead 0-alive\"] for p in patients])\n",
    "# Sort by dead/alive first, then by diagnosis\n",
    "idx = np.argsort(dead)\n",
    "idx = idx[argsort([diagnosis[i] for i in idx])]\n",
    "patients = [patients[i] for i in idx]\n",
    "\n",
    "iso_names = {1:\"Necrotic\", 2:\"Edema\", 4:\"Main Tumor\"} # What the labels actually mean\n",
    "iso_levels = [2, 4, 1] # Column order of the labels\n",
    "tumor_types = [\"Edema\", \"Main Tumor\", \"Necrotic\"]\n",
    "\n",
    "for patient in os.listdir(all_data_path):\n",
    "    print(\".\", end=\"\")\n",
    "    patient_folder_path = os.path.join(all_data_path, patient)\n",
    "    patient = patient[:-6]\n",
    "\n",
    "    tumor_seg_path = patient_folder_path + \"/\" + patient_folder_path[-20:-6] + \"_tumor_segmentation.nii.gz\"\n",
    "    if not os.path.exists(tumor_seg_path) or not patient in data:\n",
    "        continue\n",
    "    tumor_seg_nifti = nib.load(tumor_seg_path)\n",
    "    tumor_seg_mat = tumor_seg_nifti.get_fdata()\n",
    "    \n",
    "    for k, level in enumerate(iso_levels):\n",
    "        binary = tumor_seg_mat==level\n",
    "        level_name = iso_names[level]\n",
    "        B = crop_binary_volume(binary)\n",
    "        data[patient][\"B{}\".format(level_name)] = B\n",
    "        X = binary_volume_2coords(binary)\n",
    "        data[patient][\"X{}\".format(level_name)] = X\n",
    "        \n",
    "to_delete = []\n",
    "for p in data:\n",
    "    if not \"XEdema\" in data[p].keys():\n",
    "        to_delete.append(p)\n",
    "print(to_delete)\n",
    "for p in to_delete:\n",
    "    del data[p]\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4662a73b",
   "metadata": {},
   "source": [
    "## Total Persistences\n",
    "\n",
    "(TODO Later: Grab and sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aec589",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pers_type in [\"alpha\", \"cubical\"]:\n",
    "    out_dir = \"../preprocessed/{}_total\".format(pers_type)\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    for p in data:\n",
    "        fileout = \"{}/{}.pkl\".format(out_dir, p)\n",
    "        if os.path.exists(fileout):\n",
    "            continue\n",
    "        # Use precomputed persistence diagrams\n",
    "        res = pickle.load(open(\"../preprocessed/{}.pkl\".format(p), \"rb\"))\n",
    "        pers = []\n",
    "        for tumor_type in tumor_types:\n",
    "            PDs = res[\"{}_{}_PDs\".format(tumor_type, pers_type)]\n",
    "            for PD in PDs:\n",
    "                if PD.size > 0:\n",
    "                    pers.append(np.sum(PD[:, 1]-PD[:, 0]))\n",
    "                else:\n",
    "                    pers.append(0)\n",
    "        pickle.dump({\"x\":np.array(pers)}, open(fileout, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517e22fe",
   "metadata": {},
   "source": [
    "## Shape Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ffcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max = 75\n",
    "n_shells = 20\n",
    "\n",
    "out_dir = \"../preprocessed/shapehist\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "for p in data:\n",
    "    fileout = \"{}/{}.pkl\".format(out_dir, p)\n",
    "    if os.path.exists(fileout):\n",
    "        continue\n",
    "    hists = np.array([])\n",
    "    for tumor_type in tumor_types:\n",
    "        X = data[p][\"X{}\".format(tumor_type)]\n",
    "        h = get_shape_hist(X, n_shells=n_shells, r_max=r_max)\n",
    "        if hists.size == 0:\n",
    "            hists = h\n",
    "        else:\n",
    "            hists = np.concatenate((hists, h))\n",
    "    pickle.dump({\"x\":hists}, open(fileout, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd8d9f",
   "metadata": {},
   "source": [
    "## Shape Shell Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3698d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max = 75\n",
    "n_shells = 20\n",
    "subdiv = 1 # How many times to subdivide the sphere for sector points\n",
    "\n",
    "out_dir = \"../preprocessed/shapeshellhist\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "for p in data:\n",
    "    fileout = \"{}/{}.pkl\".format(out_dir, p)\n",
    "    if os.path.exists(fileout):\n",
    "        continue\n",
    "    hists = np.array([])\n",
    "    for tumor_type in tumor_types:\n",
    "        X = data[p][\"X{}\".format(tumor_type)]\n",
    "        h = get_shape_shell_hist(X, n_shells=n_shells, r_max=r_max, subdiv=subdiv)\n",
    "        print(h.shape)\n",
    "        if hists.size == 0:\n",
    "            hists = h\n",
    "        else:\n",
    "            hists = np.concatenate((hists, h))\n",
    "    pickle.dump({\"x\":hists}, open(fileout, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861923e6",
   "metadata": {},
   "source": [
    "## Shape PCA Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33eccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max = 75\n",
    "n_shells = 10\n",
    "\n",
    "out_dir = \"../preprocessed/shapehistpca\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "for p in data:\n",
    "    fileout = \"{}/{}.pkl\".format(out_dir, p)\n",
    "    if os.path.exists(fileout):\n",
    "        continue\n",
    "    hists = np.array([])\n",
    "    for tumor_type in tumor_types:\n",
    "        X = data[p][\"X{}\".format(tumor_type)]\n",
    "        h = get_shape_pca_hist(X, n_shells=n_shells, r_max=r_max)\n",
    "        if hists.size == 0:\n",
    "            hists = h\n",
    "        else:\n",
    "            hists = np.concatenate((hists, h))\n",
    "    pickle.dump({\"x\":hists}, open(fileout, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e658e8",
   "metadata": {},
   "source": [
    "## D2 Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cae4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max = 75\n",
    "n_bins = 40 # Number of bins in the histogram between [0, d_max]\n",
    "n_samples = 10000 # Number of random samples\n",
    "\n",
    "out_dir = \"../preprocessed/d2\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "for p in data:\n",
    "    fileout = \"{}/{}.pkl\".format(out_dir, p)\n",
    "    if os.path.exists(fileout):\n",
    "        continue\n",
    "    hists = np.array([])\n",
    "    for tumor_type in tumor_types:\n",
    "        X = data[p][\"X{}\".format(tumor_type)]\n",
    "        h = get_d2_hist(X, d_max=r_max*2, n_bins=n_bins, n_samples=n_samples)\n",
    "        if hists.size == 0:\n",
    "            hists = h\n",
    "        else:\n",
    "            hists = np.concatenate((hists, h))\n",
    "    pickle.dump({\"x\":hists}, open(fileout, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44256ea2",
   "metadata": {},
   "source": [
    "## Spin Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max = 75\n",
    "n_angles = 50\n",
    "dim = 64\n",
    "\n",
    "out_dir = \"../preprocessed/spinimages\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "for p in data:\n",
    "    fileout = \"{}/{}.pkl\".format(out_dir, p)\n",
    "    if os.path.exists(fileout):\n",
    "        continue\n",
    "    imgs = np.array([])\n",
    "    for tumor_type in tumor_types:\n",
    "        X = data[p][\"X{}\".format(tumor_type)]\n",
    "        img = get_spin_image(X, n_angles, r_max, dim).flatten()\n",
    "        if imgs.size == 0:\n",
    "            imgs = img\n",
    "        else:\n",
    "            imgs = np.concatenate((imgs, img))\n",
    "    pickle.dump({\"x\":imgs}, open(fileout, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea711767",
   "metadata": {},
   "source": [
    "## Connected Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_components = 10\n",
    "\n",
    "out_dir = \"../preprocessed/connectedcomponents\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "for p in data:\n",
    "    fileout = \"{}/{}.pkl\".format(out_dir, p)\n",
    "    if os.path.exists(fileout):\n",
    "        continue\n",
    "    all_counts = np.zeros(max_components*len(iso_names))\n",
    "    for i, tumor_type in enumerate(tumor_types):\n",
    "        B = data[p][\"B{}\".format(tumor_type)]\n",
    "        B = crop_binary_volume(B)\n",
    "        if B.size > 0:\n",
    "            labels = label_volume_components(B, cluster_cutoff=1)\n",
    "            counts = sorted(get_label_counts(labels).flatten())[::-1]\n",
    "            i1 = i*max_components\n",
    "            i2 = min((i+1)*max_components, i1+len(counts))\n",
    "            all_counts[i1:i2] = counts[0:(i2-i1)]\n",
    "    pickle.dump({\"x\":all_counts}, open(fileout, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1d7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
