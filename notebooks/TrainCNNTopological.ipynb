{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import ROC, AUROC\n",
    "from persim import plot_diagrams, PersistenceImager\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from datasets import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccaa11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = \"../preprocessed\"\n",
    "metadata_path = \"../Data/UCSF-PDGM-metadata_v2.csv\"\n",
    "\n",
    "#\"\"\"\n",
    "filtration_type = \"alpha\"\n",
    "imgr = PersistenceImager(pixel_size=2, birth_range=(0, 24), pers_range=(0, 24), \n",
    "                          kernel_params={'sigma':2}, weight_params={'n':1.5})\n",
    "layers = np.array([])\n",
    "lr = 1e-3\n",
    "l2_lam = 1e-2\n",
    "#\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "filtration_type = \"cubical\"\n",
    "imgr = PersistenceImager(pixel_size=0.1, birth_range=(-1,1), pers_range=(0, 2), \n",
    "                          kernel_params={'sigma':0.1}, weight_params={'n':1.5})\n",
    "layers = np.array([])\n",
    "lr = 2e-4\n",
    "l2_lam = 5e-3\n",
    "#layers = np.arange(18) # Exclude the random convolutions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "dataset_train = PImageTumorDataset(data_dir, metadata_path, imgr, filtration_type, is_training=True, layers=layers)\n",
    "dataset_test = PImageTumorDataset(data_dir, metadata_path, imgr, filtration_type, is_training=False, layers=layers)\n",
    "\n",
    "model = PImgCNNBinary(dataset_train, 3, 4)\n",
    "#model = PImgShallowCNNBinary(dataset_train, 1)\n",
    "\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "total_params = 0\n",
    "for p in model.parameters():\n",
    "    p = np.prod(list(p.shape))\n",
    "    total_params += p\n",
    "    print(p)\n",
    "print(\"Total parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196090dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "roc = ROC(task=\"binary\")\n",
    "losses = []\n",
    "accs_train = []\n",
    "accs_test = []\n",
    "aurocs_train = []\n",
    "aurocs_test = []\n",
    "for epoch in range(n_epochs):\n",
    "    model.train(True)\n",
    "    training_loader = DataLoader(dataset_train, batch_size=16, shuffle=True)\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs[:, 0, :, :, :]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_fn(outputs[:, 0], labels)\n",
    "        for p in model.parameters():\n",
    "            loss += l2_lam*torch.sum(p*p)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    acc_train = get_sigmoid_accuracy(model, dataset_train)    \n",
    "    acc_test = get_sigmoid_accuracy(model, dataset_test)\n",
    "    accs_test.append(acc_test)\n",
    "    accs_train.append(acc_train)\n",
    "    \n",
    "    auroc_train = get_auroc(model, dataset_train)    \n",
    "    auroc_test = get_auroc(model, dataset_test)\n",
    "    aurocs_test.append(auroc_test)\n",
    "    aurocs_train.append(auroc_train)\n",
    "    \n",
    "    if epoch > 0 and epoch%20 == 0:\n",
    "        print(\"loss {:.3f}\".format(total_loss), end=\", \")\n",
    "        print(\"train: {:.3f}\".format(acc_train), end=\", \")\n",
    "        print(\"test: {:.3f}\".format(acc_test))\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.subplot(311)\n",
    "        plt.plot(losses)\n",
    "        plt.title(\"Losses\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        \n",
    "        plt.subplot(312)\n",
    "        plt.plot(accs_train)\n",
    "        plt.plot(accs_test)\n",
    "        plt.legend([\"Training ({:.3f})\".format(accs_train[-1]), \"Validation ({:.3f})\".format(accs_test[-1])])\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.subplot(313)\n",
    "        plt.plot(aurocs_train)\n",
    "        plt.plot(aurocs_test)\n",
    "        plt.legend([\"Training ({:.3f})\".format(aurocs_train[-1]), \"Validation ({:.3f})\".format(aurocs_test[-1])])\n",
    "        plt.title(\"AUROC\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612d5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
